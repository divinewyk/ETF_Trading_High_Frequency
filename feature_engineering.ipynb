{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f61b0a1",
   "metadata": {},
   "source": [
    "# Final Project Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43dae8",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "434787d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import functools\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.stattools import durbin_watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c8d154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_trade_data = 'D:/academics/trading/final/trade_data/'\n",
    "where_to_save_data = 'features/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e5716",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75abee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_etf_df(etf_df):\n",
    "    \"\"\"take etf dataframe and clean it up.\"\"\"\n",
    "\n",
    "    etf_trades.drop('SYM_SUFFIX',axis=1,inplace=True)\n",
    "    etf_trades.dropna(inplace=True)\n",
    "\n",
    "    etf_df['DATE'] = pd.to_datetime(etf_df['DATE'],format='%Y%m%d')\n",
    "    etf_df['received'] = etf_df['DATE'].astype(str)+' '+etf_df['TIME_M']\n",
    "    etf_df['received'] = etf_df['received'].apply(pd.Timestamp)\n",
    "\n",
    "    etf_df['bid_ask_spread'] = etf_df['NBO']-etf_df['NBB']\n",
    "    etf_df['bid_ask_over_price'] = etf_df['bid_ask_spread']/etf_df['PRICE']\n",
    "    etf_df['bid_ask_over_price_timestamp_sum'] = etf_df.groupby('received')['bid_ask_over_price'].transform(sum)\n",
    "    etf_df['bid_ask_spread_timestamp_sum'] = etf_df.groupby('received')['bid_ask_spread'].transform(sum)\n",
    "    etf_df['dummy'] =1\n",
    "    etf_df['timestamp_count'] = etf_df.groupby('received')['dummy'].transform(sum) # trades per timestamp\n",
    "    etf_df['timestamp_volume'] = etf_df.groupby('received')['SIZE'].transform(sum) # volume in timestamp\n",
    "\n",
    "    etf_df.sort_values(['received','TR_SEQNUM'],inplace=True)\n",
    "    etf_df['cumulative_trade_count'] = etf_df['dummy'].cumsum()\n",
    "    etf_df['cumulative_volume'] = etf_df['SIZE'].cumsum() # cumulative volume\n",
    "\n",
    "    for i in [1,2]:  # 1 lag, then 2 lag\n",
    "        where0 = (etf_df.LeeReady==0)\n",
    "        lag = etf_df.shift(i)\n",
    "        # curr price is lower than prev price (seller initiated (-1))\n",
    "        etf_df[f\"lag{i}\"] = (etf_df[where0].PRICE < lag[where0].PRICE) * -1\n",
    "        # curr price is higher than prev price (buyer initiated (+1))\n",
    "        etf_df[f\"lag{i}\"] += (etf_df[where0].PRICE > lag[where0].PRICE) * 1\n",
    "        etf_df[f\"lag{i}\"] = etf_df[f\"lag{i}\"].fillna(0)\n",
    "\n",
    "        etf_df.LeeReady += etf_df[f\"lag{i}\"]\n",
    "\n",
    "    etf_df = etf_df.drop(columns=[f\"lag{i}\"])\n",
    "\n",
    "    etf_df['direction_size'] = etf_df['SIZE']*etf_df['LeeReady']\n",
    "    etf_df['direction_size'] = etf_df.groupby('received')['direction_size'].transform(sum) # sum per timestamp\n",
    "    \n",
    "    etf_df['dollar_direction'] = etf_df['PRICE']*etf_df['SIZE']*etf_df['LeeReady']\n",
    "    etf_df['dollar_direction'] = etf_df.groupby('received')['dollar_direction'].transform(sum) # sum per timestamp\n",
    "    \n",
    "    etf_df = etf_df.groupby('received').tail(1) # take last trade per timestamp\n",
    "    etf_df.set_index('received',inplace=True) # set index to received timestamp\n",
    "\n",
    "    time_criteria = (((etf_df.index.hour >= 9)&(etf_df.index.minute >= 30))|\n",
    "                     (etf_df.index.hour>9))&(etf_df.index.hour < 16)\n",
    "\n",
    "    etf_df = etf_df.loc[time_criteria].sort_index()\n",
    "    \n",
    "    etf_df['order_imbalance'] = (etf_df['NBBqty']-etf_df['NBOqty'])/etf_df['NBBqty']+etf_df['NBOqty']\n",
    "    \n",
    "    return etf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b53d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trades_in_period(trade_counts,Tau):\n",
    "    \"\"\"Take count of trades and find how many were in the prior Tau time interval.\"\"\"\n",
    "    cumulative_trade_count = trade_counts.cumsum()\n",
    "    \n",
    "    T_cumulative_trade_count = cumulative_trade_count.reindex(cumulative_trade_count.index-pd.Timedelta(Tau), method='bfill')\n",
    "    T_cumulative_trade_count.index = cumulative_trade_count.index\n",
    "\n",
    "    trades_in_period = cumulative_trade_count-T_cumulative_trade_count\n",
    "    \n",
    "    return trades_in_period\n",
    "\n",
    "def tau_average(field,trade_counts,Tau):\n",
    "    field_cum = field.cumsum()\n",
    "    T_field_cum = field_cum.reindex(field_cum.index-pd.Timedelta(Tau), method='bfill')\n",
    "    T_field_cum.index = field_cum.index\n",
    "\n",
    "    field_sum_in_period = field_cum-T_field_cum\n",
    "    trades_in_period = calc_trades_in_period(trade_counts,Tau)\n",
    "\n",
    "    tau_mean_field = field_sum_in_period/trades_in_period\n",
    "    \n",
    "    return tau_mean_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6607f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tau_trade_flow(cummulative_trades,Tau):\n",
    "    \"\"\"Calculate trade flow from cummulative trade sides over Tau time period.\"\"\"\n",
    "\n",
    "    T_cummulative_trades = cummulative_trades.reindex(cummulative_trades.index-pd.Timedelta(Tau), method='bfill')\n",
    "    T_cummulative_trades.index = cummulative_trades.index\n",
    "\n",
    "    trade_flow = cummulative_trades-T_cummulative_trades\n",
    "    trade_flow_i = trade_flow.shift(1)\n",
    "    \n",
    "    trade_flow_i.name = 'flow'\n",
    "    \n",
    "    return trade_flow_i\n",
    "\n",
    "def T_ewm_vol(price_series,T):\n",
    "    \"\"\"Calculate cum log returns up to and not including T.\n",
    "        EWMVar: Mean squared T return with decay = T.\n",
    "        Vol = square root of EWMVar.\"\"\"\n",
    "    #avoid jumps in the return series from close to open (could remove if we want to include these)\n",
    "    new_day = np.where(price_series.reset_index()['received'].dt.day.diff()!=0,np.nan,1)\n",
    "    returns = np.log(price_series/price_series.shift()) * new_day\n",
    "    T_returns = returns.rolling(T,closed='left').sum()\n",
    "    \n",
    "    ewm_var = (T_returns**2).ewm(halflife = T, times=returns.index,ignore_na=True).mean()\n",
    "    ewm_vol = np.sqrt(ewm_var)\n",
    "    ewm_vol.name = 'exp weighted volatility'\n",
    "    return ewm_vol\n",
    "\n",
    "def T_fwd_rtn(price_series,T):\n",
    "    \"\"\"Calculate T forward returns\"\"\"\n",
    "\n",
    "    T_fwd_prices = price_series.reindex(price_series.index+pd.Timedelta(T), method='ffill')\n",
    "    T_fwd_prices.index = price_series.index\n",
    "    T_fwd_rtns = T_fwd_prices/price_series-1\n",
    "    \n",
    "    T_fwd_rtns.name = 'fwd_rtn'\n",
    "\n",
    "    return T_fwd_rtns\n",
    "\n",
    "def T_rtn(price_series,T):\n",
    "    \"\"\"Calculate T forward returns\"\"\"\n",
    "\n",
    "    T_prices = price_series.reindex(price_series.index-pd.Timedelta(T), method='bfill')\n",
    "    T_prices.index = price_series.index\n",
    "    T_rtns = price_series/T_prices-1\n",
    "    \n",
    "    T_rtns.name = 'rtn'\n",
    "\n",
    "    return T_fwd_rtns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c44dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fwd_rtns(etf_trades):\n",
    "    \"Calculate different forward return periods\"\n",
    "    fwd_rtns_5min = T_fwd_rtn(etf_trades['PRICE'],'300s')\n",
    "    fwd_rtns_10min = T_fwd_rtn(etf_trades['PRICE'],'600s')\n",
    "    fwd_rtns_15min = T_fwd_rtn(etf_trades['PRICE'],'900s')\n",
    "    \n",
    "    fwd_rtns = pd.concat([fwd_rtns_5min, fwd_rtns_10min, fwd_rtns_15min],axis=1)\n",
    "    fwd_rtns.columns = ['fwd_rtn_5min','fwd_rtn_10min','fwd_rtn_15min']\n",
    "    fwd_rtns.sort_index(inplace=True)\n",
    "    \n",
    "    return fwd_rtns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5dbc4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ewm_vol(price_series):\n",
    "    \"\"\"Calculate EWMA Volatility Metrics\"\"\"\n",
    "    \n",
    "    intervals = [1,2,4,5,15,20,25,30,45,60]\n",
    "    times = [str(60*t)+'s' for t in intervals]\n",
    "    vols = pd.DataFrame(index=price_series.index)\n",
    "    for time,interval in zip(times,intervals):\n",
    "        annualize = 6.5*(60/interval)*252\n",
    "        vols['ewm_vol_'+time] = np.sqrt(T_ewm_vol(price_series,time)**2*annualize).replace(0,np.nan)\n",
    "    \n",
    "    return vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6c6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_flow_metrics(sized_directions,dollar_sized_directions):\n",
    "    \"\"\"Calculate Flow Metrics\"\"\"\n",
    "    \n",
    "    dollar_flow_1min = tau_trade_flow((dollar_sized_directions).cumsum(),'60s')\n",
    "    dollar_flow_2min = tau_trade_flow((dollar_sized_directions).cumsum(),'120s')\n",
    "    dollar_flow_4min = tau_trade_flow((dollar_sized_directions).cumsum(),'240s')\n",
    "    dollar_flow_5min = tau_trade_flow((dollar_sized_directions).cumsum(),'300s')\n",
    "    dollar_flow_15min = tau_trade_flow((dollar_sized_directions).cumsum(),'900s')\n",
    "    dollar_flow_20min = tau_trade_flow((dollar_sized_directions).cumsum(),'1200s')\n",
    "    dollar_flow_25min = tau_trade_flow((dollar_sized_directions).cumsum(),'1500s')\n",
    "    dollar_flow_30min = tau_trade_flow((dollar_sized_directions).cumsum(),'1800s')\n",
    "    dollar_flow_45min = tau_trade_flow((dollar_sized_directions).cumsum(),'2700s')\n",
    "    dollar_flow_60min = tau_trade_flow((dollar_sized_directions).cumsum(),'3600s')\n",
    "    \n",
    "    flow_1min = tau_trade_flow((sized_directions).cumsum(),'60s')\n",
    "    flow_2min = tau_trade_flow((sized_directions).cumsum(),'120s')\n",
    "    flow_4min = tau_trade_flow((sized_directions).cumsum(),'240s')\n",
    "    flow_5min = tau_trade_flow((sized_directions).cumsum(),'300s')\n",
    "    flow_15min = tau_trade_flow((sized_directions).cumsum(),'900s')\n",
    "    flow_20min = tau_trade_flow((sized_directions).cumsum(),'1200s')\n",
    "    flow_25min = tau_trade_flow((sized_directions).cumsum(),'1500s')\n",
    "    flow_30min = tau_trade_flow((sized_directions).cumsum(),'1800s')\n",
    "    flow_45min = tau_trade_flow((sized_directions).cumsum(),'2700s')\n",
    "    flow_60min = tau_trade_flow((sized_directions).cumsum(),'3600s')\n",
    "\n",
    "    flow_1min_EWMA = flow_1min.ewm(halflife='120s',times=flow_1min.index).mean()\n",
    "    flow_2min_EWMA = flow_2min.ewm(halflife='240s',times=flow_2min.index).mean()\n",
    "    flow_4min_EWMA = flow_4min.ewm(halflife='480s',times=flow_4min.index).mean()\n",
    "    flow_5min_EWMA = flow_5min.ewm(halflife='600s',times=flow_5min.index).mean()\n",
    "    flow_15min_EWMA = flow_15min.ewm(halflife='1800s',times=flow_15min.index).mean()\n",
    "    flow_20min_EWMA = flow_20min.ewm(halflife='2400s',times=flow_20min.index).mean()\n",
    "    flow_25min_EWMA = flow_25min.ewm(halflife='3000s',times=flow_25min.index).mean()\n",
    "    flow_30min_EWMA = flow_30min.ewm(halflife='3600s',times=flow_30min.index).mean()\n",
    "    flow_45min_EWMA = flow_45min.ewm(halflife='5400s',times=flow_45min.index).mean()\n",
    "    flow_60min_EWMA = flow_60min.ewm(halflife='7200s',times=flow_60min.index).mean()\n",
    "    \n",
    "    dollar_flows = pd.concat([dollar_flow_1min,dollar_flow_2min,dollar_flow_4min,dollar_flow_5min, dollar_flow_15min,\n",
    "                              dollar_flow_20min,dollar_flow_25min, dollar_flow_30min, dollar_flow_45min, dollar_flow_60min],\n",
    "                             axis=1)\n",
    "    dollar_flows.columns = ['dollar_flow_1min','dollar_flow_2min','dollar_flow_4min','dollar_flow_5min',\n",
    "                            'dollar_flow_15min','dollar_flow_20min','dollar_flow_25min','dollar_flow_30min',\n",
    "                            'dollar_flow_45min','dollar_flow_60min']\n",
    "    \n",
    "    flows = pd.concat([flow_1min,flow_2min,flow_4min,flow_5min, flow_15min, flow_20min,\n",
    "                       flow_25min, flow_30min, flow_45min, flow_60min],\n",
    "                      axis=1)\n",
    "    flows.columns = ['flow_1min','flow_2min','flow_4min','flow_5min','flow_15min','flow_20min',\n",
    "                     'flow_25min', 'flow_30min', 'flow_45min', 'flow_60min']\n",
    "\n",
    "    EWMA_flows = pd.concat([flow_1min_EWMA,flow_2min_EWMA,flow_4min_EWMA,flow_5min_EWMA, flow_15min_EWMA,\n",
    "                            flow_20min_EWMA,flow_25min_EWMA, flow_30min_EWMA, flow_45min_EWMA, flow_60min_EWMA],\n",
    "                           axis=1)\n",
    "    \n",
    "    EWMA_flows.columns = ['EWMA_flow_1min','EWMA_flow_2min','EWMA_flow_4min','EWMA_flow_5min','EWMA_flow_15min',\n",
    "                          'EWMA_flow_20min','EWMA_flow_25min', 'EWMA_flow_30min', 'EWMA_flow_45min', 'EWMA_flow_60min']\n",
    "\n",
    "    all_flows = flows.join([EWMA_flows,dollar_flows])\n",
    "    \n",
    "    return all_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2221f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bid_ask_metrics(bid_ask_spread_sum, bid_ask_over_price_sum, trade_counts):\n",
    "    \n",
    "    bid_ask_1min = tau_average(field=bid_ask_spread_sum, trade_counts=trade_counts, Tau='60s')\n",
    "    bid_ask_2min = tau_average(field=bid_ask_spread_sum, trade_counts=trade_counts, Tau='120s')\n",
    "    bid_ask_5min = tau_average(field=bid_ask_spread_sum, trade_counts=trade_counts, Tau='300s')\n",
    "    bid_ask_10min = tau_average(field=bid_ask_spread_sum, trade_counts=trade_counts, Tau='600s')\n",
    "    bid_ask_15min = tau_average(field=bid_ask_spread_sum, trade_counts=trade_counts, Tau='900s')\n",
    "    bid_ask_30min = tau_average(field=bid_ask_spread_sum, trade_counts=trade_counts, Tau='1800s')\n",
    "    bid_ask_60min = tau_average(field=bid_ask_spread_sum, trade_counts=trade_counts, Tau='3600s')\n",
    "\n",
    "    bid_ask = pd.concat([bid_ask_1min, bid_ask_2min, bid_ask_5min, bid_ask_10min,\n",
    "                         bid_ask_15min, bid_ask_30min, bid_ask_60min], axis=1)\n",
    "\n",
    "    bid_ask.columns = ['avg_bid_ask_1min','avg_bid_ask_2min','avg_bid_ask_5min','avg_bid_ask_10min',\n",
    "                       'avg_bid_ask_15min','avg_bid_ask_30min','avg_bid_ask_60min']    \n",
    "    \n",
    "    bid_ask_price_1min = tau_average(field=bid_ask_over_price_sum,trade_counts=trade_counts,Tau='60s')\n",
    "    bid_ask_price_2min = tau_average(field=bid_ask_over_price_sum,trade_counts=trade_counts,Tau='120s')\n",
    "    bid_ask_price_5min = tau_average(field=bid_ask_over_price_sum,trade_counts=trade_counts,Tau='300s')\n",
    "    bid_ask_price_10min = tau_average(field=bid_ask_over_price_sum,trade_counts=trade_counts,Tau='600s')\n",
    "    bid_ask_price_15min = tau_average(field=bid_ask_over_price_sum,trade_counts=trade_counts,Tau='900s')\n",
    "    bid_ask_price_30min = tau_average(field=bid_ask_over_price_sum,trade_counts=trade_counts,Tau='1800s')\n",
    "    bid_ask_price_60min = tau_average(field=bid_ask_over_price_sum,trade_counts=trade_counts,Tau='3600s')\n",
    "    \n",
    "    bid_ask_price = pd.concat([bid_ask_price_1min, bid_ask_price_2min, bid_ask_price_5min, bid_ask_price_10min,\n",
    "                           bid_ask_price_15min, bid_ask_30min, bid_ask_price_60min], axis=1)\n",
    "\n",
    "    bid_ask_price.columns = ['avg_bid_ask_price_1min','avg_bid_ask_price_2min','avg_bid_ask_price_5min',\n",
    "                             'avg_bid_ask_price_10min','avg_bid_ask_price_15min','avg_bid_ask_price_30min',\n",
    "                             'avg_bid_ask_price_60min']\n",
    "\n",
    "    bid_ask = pd.concat([bid_ask_1min, bid_ask_2min, bid_ask_5min, bid_ask_10min,\n",
    "                         bid_ask_15min, bid_ask_30min, bid_ask_60min], axis=1)\n",
    "\n",
    "    bid_ask.columns = ['avg_bid_ask_1min','avg_bid_ask_2min','avg_bid_ask_5min','avg_bid_ask_10min',\n",
    "                       'avg_bid_ask_15min','avg_bid_ask_30min','avg_bid_ask_60min']\n",
    "\n",
    "    bid_ask_met = bid_ask_price.join(bid_ask)\n",
    "    \n",
    "    return bid_ask_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96e378eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_imbalance_metrics(imbalances, trade_counts):\n",
    "    \"\"\"Calculate tau time period average order imbalances. for 1,2,4,5,10,15,30 minutes\"\"\"\n",
    "    order_imbalance_1min = tau_average(imbalances, trade_counts, '60s')\n",
    "    order_imbalance_2min = tau_average(imbalances, trade_counts, '120s')\n",
    "    order_imbalance_4min = tau_average(imbalances, trade_counts, '240s')\n",
    "    order_imbalance_5min = tau_average(imbalances, trade_counts, '300s')\n",
    "    order_imbalance_10min = tau_average(imbalances, trade_counts, '600s')\n",
    "    order_imbalance_15min = tau_average(imbalances, trade_counts, '900s')\n",
    "    order_imbalance_30min = tau_average(imbalances, trade_counts, '1800s')\n",
    "\n",
    "    order_imbalances = pd.concat([order_imbalance_1min,order_imbalance_2min, order_imbalance_4min,order_imbalance_5min,\n",
    "                                  order_imbalance_10min, order_imbalance_15min, order_imbalance_30min], axis=1)\n",
    "    \n",
    "    order_imbalances.columns = ['order_imbalance_1min','order_imbalance_2min','order_imbalance_4min','order_imbalance_5min',\n",
    "                                'order_imbalance_10min', 'order_imbalance_15min', 'order_imbalance_30min']\n",
    "    \n",
    "    return order_imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51ac61d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_all_metrics(etf_trades, iNAV):\n",
    "    \"\"\"Calculate all the trade data metrics, forward returns, and join it together.\"\"\"\n",
    "    etf_trades = clean_etf_df(etf_trades)\n",
    "\n",
    "    flow_metrics = calc_flow_metrics(sized_directions = etf_trades['direction_size'],\n",
    "                                     dollar_sized_directions = etf_trades['dollar_direction'])\n",
    "\n",
    "    bid_ask_metrics = calc_bid_ask_metrics(bid_ask_spread_sum = etf_trades['bid_ask_spread_timestamp_sum'],\n",
    "                                           bid_ask_over_price_sum = etf_trades['bid_ask_over_price_timestamp_sum'],\n",
    "                                           trade_counts = etf_trades['timestamp_count'])\n",
    "    \n",
    "    vol_metrics = calc_ewm_vol(price_series = etf_trades['PRICE'])\n",
    "\n",
    "    fields_from_trade_book = etf_trades.loc[:,['PRICE','NBB','NBO','NBOqty','NBBqty',\n",
    "                                               'cumulative_trade_count','cumulative_volume','order_imbalance']]\n",
    "    \n",
    "    order_imbalances = calc_imbalance_metrics(etf_trades['order_imbalance'], \n",
    "                                              trade_counts=etf_trades['timestamp_count'])\n",
    "    \n",
    "    # join all the fields from trade book together\n",
    "    trade_book_variables = flow_metrics.join([bid_ask_metrics,vol_metrics,fields_from_trade_book])\n",
    "    \n",
    "    independent_variables = pd.merge_asof(iNAV,\n",
    "                                          trade_book_variables,\n",
    "                                          left_index=True,\n",
    "                                          right_index=True,\n",
    "                                          direction='backward',\n",
    "                                          allow_exact_matches=False)\n",
    "\n",
    "    independent_variables['nav_discount_bid'] = independent_variables['NBB']/independent_variables['iNAV']-1\n",
    "    independent_variables['nav_discount_ask'] = independent_variables['NBO']/independent_variables['iNAV']-1\n",
    "    \n",
    "    fwd_rtns = calc_fwd_rtns(etf_trades)\n",
    "    \n",
    "    fwd_rtns.index = fwd_rtns.index - pd.Timedelta(50,'milli') # subtract 15 milliseconds for latency\n",
    "\n",
    "    all_vars = pd.merge_asof(independent_variables,\n",
    "                             fwd_rtns,\n",
    "                             left_index=True,\n",
    "                             right_index=True,\n",
    "                             direction='forward',\n",
    "                             allow_exact_matches=False).dropna()\n",
    "    \n",
    "    return all_vars "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca324a",
   "metadata": {},
   "source": [
    "#### HYG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88779c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYG\n",
    "etf_trades = pd.read_csv(path_to_trade_data+'HYG_2020.csv')\n",
    "\n",
    "etf_iNAV = pd.read_csv('iNAVs/hygiv.csv', index_col = 'date',parse_dates=True)\n",
    "iNAV = etf_iNAV.loc[:,'iNAV']\n",
    "\n",
    "all_vars = calc_all_metrics(etf_trades = etf_trades, iNAV=iNAV)\n",
    "all_vars.to_csv(where_to_save_data+'HYG_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd55906c",
   "metadata": {},
   "source": [
    "#### JNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba658b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_trades = pd.read_csv(path_to_trade_data+'JNK_2020.csv')\n",
    "\n",
    "etf_iNAV = pd.read_csv('iNAVs/jnkiv.csv', index_col = 'date',parse_dates=True)\n",
    "iNAV = etf_iNAV.loc[:,'iNAV']\n",
    "\n",
    "all_vars = calc_all_metrics(etf_trades = etf_trades, iNAV=iNAV)\n",
    "all_vars.to_csv(where_to_save_data+'JNK_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65db43f2",
   "metadata": {},
   "source": [
    "#### BKLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d50a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_trades = pd.read_csv(path_to_trade_data+'BKLN_2020.csv')\n",
    "\n",
    "etf_iNAV = pd.read_csv('iNAVs/bklniv.csv', index_col = 'date',parse_dates=True)\n",
    "iNAV = etf_iNAV.loc[:,'iNAV']\n",
    "\n",
    "all_vars = calc_all_metrics(etf_trades = etf_trades, iNAV=iNAV)\n",
    "all_vars.to_csv(where_to_save_data+'BKLN_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22bb91d",
   "metadata": {},
   "source": [
    "#### SRLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b6c45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_trades = pd.read_csv(path_to_trade_data+'SRLN_2020.csv')\n",
    "\n",
    "etf_iNAV = pd.read_csv('iNAVs/srlniv.csv', index_col = 'date',parse_dates=True)\n",
    "iNAV = etf_iNAV.loc[:,'iNAV']\n",
    "\n",
    "all_vars = calc_all_metrics(etf_trades = etf_trades, iNAV=iNAV)\n",
    "all_vars.to_csv(where_to_save_data+'SRLN_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b67eed",
   "metadata": {},
   "source": [
    "#### PFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d55526d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_trades = pd.read_csv(path_to_trade_data+'PFF_2020.csv')\n",
    "\n",
    "etf_iNAV = pd.read_csv('iNAVs/pffiv.csv', index_col = 'date',parse_dates=True)\n",
    "iNAV = etf_iNAV.loc[:,'iNAV']\n",
    "\n",
    "all_vars = calc_all_metrics(etf_trades = etf_trades, iNAV=iNAV)\n",
    "all_vars.to_csv(where_to_save_data+'PFF_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d5979",
   "metadata": {},
   "source": [
    "#### PGX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb7bd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_trades = pd.read_csv(path_to_trade_data+'PGX_2020.csv')\n",
    "\n",
    "etf_iNAV = pd.read_csv('iNAVs/pgxiv.csv', index_col = 'date',parse_dates=True)\n",
    "iNAV = etf_iNAV.loc[:,'iNAV']\n",
    "\n",
    "all_vars = calc_all_metrics(etf_trades = etf_trades, iNAV=iNAV)\n",
    "all_vars.to_csv(where_to_save_data+'PGX_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295623e9",
   "metadata": {},
   "source": [
    "#### SPHY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc17a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_trades = pd.read_csv(path_to_trade_data+'SPHY_2020.csv')\n",
    "\n",
    "etf_iNAV = pd.read_csv('iNAVs/sphyiv.csv', index_col = 'date',parse_dates=True)\n",
    "iNAV = etf_iNAV.loc[:,'iNAV']\n",
    "\n",
    "all_vars = calc_all_metrics(etf_trades = etf_trades, iNAV=iNAV)\n",
    "all_vars.to_csv(where_to_save_data+'SPHY_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a93b7",
   "metadata": {},
   "source": [
    "#### HYGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5560dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_trades = pd.read_csv(path_to_trade_data+'HYGH_2020.csv')\n",
    "\n",
    "etf_iNAV = pd.read_csv('iNAVs/hyghiv.csv', index_col = 'date',parse_dates=True)\n",
    "iNAV = etf_iNAV.loc[:,'iNAV']\n",
    "\n",
    "all_vars = calc_all_metrics(etf_trades = etf_trades, iNAV=iNAV)\n",
    "all_vars.to_csv(where_to_save_data+'HYGH_metrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
